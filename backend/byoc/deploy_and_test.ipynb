{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Create your container repository\n",
    "\n",
    "open aws console and create a repository for your container: https://us-west-2.console.aws.amazon.com/ecr/create-repository?region=us-west-2\n",
    "\n",
    "for example `236995464743.dkr.ecr.us-west-2.amazonaws.com/sagemaker_endpoint/vllm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# login\n",
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 434444145045.dkr.ecr.us-east-1.amazonaws.com\n",
    "\n",
    "VLLM_VERSION = \"v0.5.5\"\n",
    "REPO_NAME = \"sagemaker_endpoint/vllm\"\n",
    "CONTAINER = f\"434444145045.dkr.ecr.us-east-1.amazonaws.com/{REPO_NAME}:{VLLM_VERSION}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "demo codes are in `app/`\n",
    "build and push the docker with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker build --build-arg VLLM_VERSION={VLLM_VERSION} -t {REPO_NAME}:{VLLM_VERSION} .\n",
    "!docker tag {REPO_NAME}:{VLLM_VERSION} {CONTAINER}\n",
    "!docker push {CONTAINER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'USER': 'ubuntu', 'SSH_CLIENT': '111.198.223.106 58543 22', 'XDG_SESSION_TYPE': 'tty', 'SHLVL': '2', 'HOME': '/home/ubuntu', 'SSL_CERT_FILE': '/usr/lib/ssl/cert.pem', 'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus', 'LOGNAME': 'ubuntu', '_': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/bin/python', 'XDG_SESSION_CLASS': 'user', 'VSCODE_CLI_REQUIRE_TOKEN': '08749abe-85df-47fe-a1e0-ea3c34d7468b', 'XDG_SESSION_ID': '2809', 'PATH': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/bin:/home/ubuntu/workspace/llm_model_hub/miniconda3/condabin:/home/ubuntu/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/bin/remote-cli:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin', 'VSCODE_AGENT_FOLDER': '/home/ubuntu/.vscode-server', 'XDG_RUNTIME_DIR': '/run/user/1000', 'SSL_CERT_DIR': '/usr/lib/ssl/certs', 'LANG': 'C.UTF-8', 'SHELL': '/bin/bash', 'PWD': '/home/ubuntu', 'SSH_CONNECTION': '111.198.223.106 58543 172.31.38.107 22', 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop', 'VSCODE_CWD': '/home/ubuntu', 'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en\",\"osLocale\":\"en\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/home/ubuntu/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/nls.messages.json\",\"locale\":\"en\",\"availableLanguages\":{}}', 'VSCODE_HANDLES_SIGPIPE': 'true', 'LS_COLORS': '', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', 'LESSOPEN': '| /usr/bin/lesspipe %s', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'BROWSER': '/home/ubuntu/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/bin/helpers/browser.sh', 'ELECTRON_RUN_AS_NODE': '1', 'VSCODE_IPC_HOOK_CLI': '/run/user/1000/vscode-ipc-2b2e11d6-12f1-4b9f-b5ec-f042621b2581.sock', 'PYTHONUNBUFFERED': '1', 'CONDA_EXE': '/home/ubuntu/workspace/llm_model_hub/miniconda3/bin/conda', '_CE_M': '', 'CONDA_ROOT': '/home/ubuntu/workspace/llm_model_hub/miniconda3', 'CONDA_PREFIX': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311', 'CONDA_PROMPT_MODIFIER': '(py311) ', '_CE_CONDA': '', 'PYTHONIOENCODING': 'utf-8', 'CONDA_SHLVL': '2', 'CONDA_PYTHON_EXE': '/home/ubuntu/workspace/llm_model_hub/miniconda3/bin/python', 'REACT_APP_API_KEY': 'f1e16e1e6214d7c44d078b1f0607b2388f29d729', 'CONDA_DEFAULT_ENV': 'py311', 'CONDA_PREFIX_1': '/home/ubuntu/workspace/llm_model_hub/miniconda3', 'REACT_APP_API_ENDPOINT': 'http://ec2-3-93-192-33.compute-1.amazonaws.com:443/v1', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHON_FROZEN_MODULES': 'on', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'AK': '', 'SK': '', 'profile': '', 'region': 'us-east-1', 'role': 'arn:aws:iam::434444145045:role/sagemaker-modelhub', 'db_host': '127.0.0.1', 'db_name': 'llm', 'db_user': 'llmdata', 'db_password': 'llmdata', 'api_keys': 'f1e16e1e6214d7c44d078b1f0607b2388f29d729', 'HUGGING_FACE_HUB_TOKEN': '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', 'WANDB_API_KEY': 'e83b1e4fa169b00634e57a8eea9fe60c4a0ffb31', 'vllm_image': '434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.5.5', 'model_artifact': 's3://sagemaker-us-east-1-434444145045/sagemaker_endpoint/vllm//model.tar.gz', 'MAX_MODEL_LEN': '12288'})\n"
     ]
    }
   ],
   "source": [
    "# !pip install boto3 sagemaker transformers\n",
    "import re\n",
    "import json\n",
    "import os,dotenv\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "print(os.environ)\n",
    "\n",
    "boto_sess = boto3.Session(\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "sess = sagemaker.session.Session(boto_session=boto_sess)\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = os.environ.get('role')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare model file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: deploy vllm by scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo the entrypoint of the endpoint is \"start.sh\"\n",
    "!echo ====================================================\n",
    "!cat vllm_by_scripts/start.sh\n",
    "!echo ====================================================\n",
    "\n",
    "!rm vllm_by_scripts.tar.gz\n",
    "!tar czvf vllm_by_scripts.tar.gz vllm_by_scripts/\n",
    "\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/vllm/\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"vllm_by_scripts.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: deploy vllm by model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo write the model_id to file \"model_id\"\n",
    "!echo ====================================================\n",
    "!cat vllm_by_model_id/model_id\n",
    "!echo ====================================================\n",
    "!echo \n",
    "!echo write envs to file \".env\"\n",
    "!echo ====================================================\n",
    "!cat vllm_by_model_id/.env\n",
    "!echo ====================================================\n",
    "\n",
    "!rm vllm_by_model_id.tar.gz\n",
    "!tar czvf vllm_by_model_id.tar.gz vllm_by_model_id/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_dir/\n",
      "dummy_dir/env\n",
      "dummy_dir/s5cmd\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p dummy_dir\n",
    "!cd dummy_dir && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf model.tar.gz dummy_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-434444145045/sagemaker_endpoint/vllm//model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/vllm/\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.5.5'\n",
    "# model = Model(\n",
    "#     name=sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"_model\",\n",
    "#     model_data=code_artifact,\n",
    "#     image_uri=CONTAINER,\n",
    "#     role=role,\n",
    "#     sagemaker_session=sess,\n",
    "# )\n",
    "\n",
    "# # 部署模型到endpoint\n",
    "# endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"_endpoint\"\n",
    "# print(f\"endpoint_name: {endpoint_name}\")\n",
    "# predictor = model.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.g5.2xlarge',\n",
    "#     endpoint_name=endpoint_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test deployment from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint_name: sagemaker-vllm-2024-09-03-14-18-30-001-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.5.5'\n",
    "model_path = \"s3://sagemaker-us-east-1-434444145045/Qwen2-1-5B-Instruct/6d0410c634ea438fa5018072e84c10a6/finetuned_model_merged/\"\n",
    "# model_id=\"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "model_id = 'Qwen/Qwen2-1.5B-Instruct'\n",
    "env={\n",
    "    \"HF_MODEL_ID\": model_id,\n",
    "    \"S3_MODEL_PATH\":model_path,\n",
    "}\n",
    "model = Model(\n",
    "    name=sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"-model\",\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env=env,\n",
    ")\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"-endpoint\"\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "you can invoke your model with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is a quick sort function in Python:\n",
      "```python\n",
      "def quicksort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "\n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "```\n",
      "\n",
      "This function takes an array as input and returns the sorted array. The function first checks if the input array has length 0 or 1, in which case it returns the array as it is. Otherwise, it chooses a pivot element from the array, which is the middle element in this case. It then separates the elements in the array into three groups: elements less than the pivot, elements equal to the pivot, and elements greater than the pivot. It then recursively applies the quicksort function to the left and right sub-arrays, and finally combines the three sorted sub-arrays to produce the final sorted array.\n",
      "```makefile\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "runtime = boto3.client('runtime.sagemaker',region_name='us-east-1')\n",
    "endpoint_name = \"Meta-Llama-3-1-8B-Instruct-2024-09-04-10-26-26-004\"\n",
    "payload = {\n",
    "    # \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"model\":\"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a simple implementation of Quick Sort in Python:\n",
      "\n",
      "```python\n",
      "def quickSort(arr):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[len(arr) // 2]\n",
      "        left = [x for x in arr if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr if x > pivot]\n",
      "        return quickSort(left) + middle + quickSort(right)\n",
      "```\n",
      "\n",
      "This function works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted."
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    # \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "     \"model\":\"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Completion api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Completion api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.end()\n",
    "            # print(data)\n",
    "            print(data[\"choices\"][0][\"text\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
